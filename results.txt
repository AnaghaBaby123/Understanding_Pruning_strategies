-------------------------------------- 50 epochs------------------------------------------------------

Epoch 01 — train_loss: 3.6061, val_loss: 3.3556
Epoch 02 — train_loss: 3.0324, val_loss: 2.7835
Epoch 03 — train_loss: 2.4560, val_loss: 2.2406
Epoch 04 — train_loss: 2.0332, val_loss: 1.8588
Epoch 05 — train_loss: 1.7287, val_loss: 1.5675
Epoch 06 — train_loss: 1.4789, val_loss: 1.3167
Epoch 07 — train_loss: 1.2651, val_loss: 1.0819
Epoch 08 — train_loss: 1.0829, val_loss: 0.8775
Epoch 09 — train_loss: 0.9203, val_loss: 0.7237
Epoch 10 — train_loss: 0.7840, val_loss: 0.5959
Epoch 11 — train_loss: 0.6643, val_loss: 0.4710
Epoch 12 — train_loss: 0.5730, val_loss: 0.3916
Epoch 13 — train_loss: 0.4921, val_loss: 0.3140
Epoch 14 — train_loss: 0.4266, val_loss: 0.2611
Epoch 15 — train_loss: 0.3767, val_loss: 0.2222
Epoch 16 — train_loss: 0.3256, val_loss: 0.1834
Epoch 17 — train_loss: 0.2930, val_loss: 0.1572
Epoch 18 — train_loss: 0.2657, val_loss: 0.1319
Epoch 19 — train_loss: 0.2392, val_loss: 0.1134
Epoch 20 — train_loss: 0.2170, val_loss: 0.1014
Epoch 21 — train_loss: 0.1929, val_loss: 0.0877
Epoch 22 — train_loss: 0.1756, val_loss: 0.0822
Epoch 23 — train_loss: 0.1701, val_loss: 0.0700
Epoch 24 — train_loss: 0.1536, val_loss: 0.0631
Epoch 25 — train_loss: 0.1420, val_loss: 0.0563
Epoch 26 — train_loss: 0.1334, val_loss: 0.0532
Epoch 27 — train_loss: 0.1221, val_loss: 0.0473
Epoch 28 — train_loss: 0.1137, val_loss: 0.0461
Epoch 29 — train_loss: 0.1087, val_loss: 0.0422
Epoch 30 — train_loss: 0.1013, val_loss: 0.0387
Epoch 31 — train_loss: 0.0994, val_loss: 0.0347
Epoch 32 — train_loss: 0.0910, val_loss: 0.0335
Epoch 33 — train_loss: 0.0843, val_loss: 0.0309
Epoch 34 — train_loss: 0.0817, val_loss: 0.0300
Epoch 35 — train_loss: 0.0753, val_loss: 0.0292
Epoch 36 — train_loss: 0.0708, val_loss: 0.0267
Epoch 37 — train_loss: 0.0672, val_loss: 0.0254
Epoch 38 — train_loss: 0.0671, val_loss: 0.0224
Epoch 39 — train_loss: 0.0604, val_loss: 0.0198
Epoch 40 — train_loss: 0.0606, val_loss: 0.0210
Epoch 41 — train_loss: 0.0584, val_loss: 0.0208
Epoch 42 — train_loss: 0.0578, val_loss: 0.0184
Epoch 43 — train_loss: 0.0540, val_loss: 0.0155
Epoch 44 — train_loss: 0.0504, val_loss: 0.0148
Epoch 45 — train_loss: 0.0492, val_loss: 0.0159
Epoch 46 — train_loss: 0.0451, val_loss: 0.0157
Epoch 47 — train_loss: 0.0443, val_loss: 0.0147
Epoch 48 — train_loss: 0.0444, val_loss: 0.0127
Epoch 49 — train_loss: 0.0425, val_loss: 0.0140
Epoch 50 — train_loss: 0.0395, val_loss: 0.0124



Total parameters: 4062631
Trainable parameters: 4062631
Model size (MB): 15.50

Test Accuracy: 96.38%
              precision    recall  f1-score   support

           0       1.00      0.95      0.97        60
           1       0.97      0.94      0.95       720
          10       1.00      1.00      1.00       660
          11       0.99      0.94      0.96       420
          12       1.00      1.00      1.00       690
          13       1.00      1.00      1.00       720
          14       0.91      1.00      0.95       270
          15       1.00      0.99      1.00       210
          16       1.00      0.99      1.00       150
          17       1.00      0.93      0.96       360
          18       0.99      0.92      0.95       390
          19       0.93      0.93      0.93        60
           2       0.93      0.97      0.95       750
          20       0.93      0.99      0.96        90
          21       0.91      0.94      0.93        90
          22       1.00      0.76      0.86       120
          23       0.95      0.97      0.96       150
          24       1.00      0.94      0.97        90
          25       0.94      0.96      0.95       480
          26       0.93      0.99      0.96       180
          27       0.62      0.50      0.56        60
          28       0.82      0.98      0.89       150
          29       0.87      0.98      0.92        90
           3       1.00      0.94      0.96       450
          30       0.91      0.91      0.91       150
          31       0.94      1.00      0.97       270
          32       0.98      1.00      0.99        60
          33       0.99      0.96      0.97       210
          34       0.87      0.99      0.93       120
          35       0.98      0.96      0.97       390
          36       1.00      0.92      0.96       120
          37       0.98      0.95      0.97        60
          38       0.98      0.99      0.98       690
          39       0.95      0.91      0.93        90
           4       0.98      0.98      0.98       660
          40       0.93      0.93      0.93        90
          41       0.92      0.93      0.93        60
          42       1.00      0.89      0.94        90
           5       0.94      0.96      0.95       630
           6       0.94      1.00      0.97       150
           7       0.98      0.95      0.97       450
           8       0.93      0.97      0.95       450
           9       0.99      0.98      0.99       480

    accuracy                           0.96     12630
   macro avg       0.95      0.95      0.95     12630
weighted avg       0.96      0.96      0.96     12630

-------------------------------------------------78 epochs-------------------------------------------------------


Epoch 01 — train_loss: 3.6253, val_loss: 3.3769
Epoch 02 — train_loss: 3.0562, val_loss: 2.7983
Epoch 03 — train_loss: 2.4858, val_loss: 2.2839
Epoch 04 — train_loss: 2.0608, val_loss: 1.9087
Epoch 05 — train_loss: 1.7388, val_loss: 1.5651
Epoch 06 — train_loss: 1.4905, val_loss: 1.3010
Epoch 07 — train_loss: 1.2764, val_loss: 1.0792
Epoch 08 — train_loss: 1.0847, val_loss: 0.8865
Epoch 09 — train_loss: 0.9298, val_loss: 0.7199
Epoch 10 — train_loss: 0.7827, val_loss: 0.5891
Epoch 11 — train_loss: 0.6805, val_loss: 0.4804
Epoch 12 — train_loss: 0.5804, val_loss: 0.3940
Epoch 13 — train_loss: 0.5016, val_loss: 0.3207
Epoch 14 — train_loss: 0.4414, val_loss: 0.2697
Epoch 15 — train_loss: 0.3879, val_loss: 0.2185
Epoch 16 — train_loss: 0.3437, val_loss: 0.1818
Epoch 17 — train_loss: 0.3071, val_loss: 0.1641
Epoch 18 — train_loss: 0.2702, val_loss: 0.1314
Epoch 19 — train_loss: 0.2455, val_loss: 0.1155
Epoch 20 — train_loss: 0.2243, val_loss: 0.0990
Epoch 21 — train_loss: 0.2062, val_loss: 0.0870
Epoch 22 — train_loss: 0.1850, val_loss: 0.0806
Epoch 23 — train_loss: 0.1736, val_loss: 0.0726
Epoch 24 — train_loss: 0.1610, val_loss: 0.0714
Epoch 25 — train_loss: 0.1491, val_loss: 0.0627
Epoch 26 — train_loss: 0.1370, val_loss: 0.0526
Epoch 27 — train_loss: 0.1251, val_loss: 0.0490
Epoch 28 — train_loss: 0.1175, val_loss: 0.0442
Epoch 29 — train_loss: 0.1145, val_loss: 0.0436
Epoch 30 — train_loss: 0.1070, val_loss: 0.0408
Epoch 31 — train_loss: 0.0993, val_loss: 0.0362
Epoch 32 — train_loss: 0.0951, val_loss: 0.0355
Epoch 33 — train_loss: 0.0919, val_loss: 0.0309
Epoch 34 — train_loss: 0.0886, val_loss: 0.0280
Epoch 35 — train_loss: 0.0794, val_loss: 0.0281
Epoch 36 — train_loss: 0.0765, val_loss: 0.0243
Epoch 37 — train_loss: 0.0721, val_loss: 0.0233
Epoch 38 — train_loss: 0.0696, val_loss: 0.0241
Epoch 39 — train_loss: 0.0666, val_loss: 0.0217
Epoch 40 — train_loss: 0.0612, val_loss: 0.0189
Epoch 41 — train_loss: 0.0622, val_loss: 0.0162
Epoch 42 — train_loss: 0.0561, val_loss: 0.0178
Epoch 43 — train_loss: 0.0546, val_loss: 0.0168
Epoch 44 — train_loss: 0.0529, val_loss: 0.0131
Epoch 45 — train_loss: 0.0503, val_loss: 0.0143
Epoch 46 — train_loss: 0.0500, val_loss: 0.0117
Epoch 47 — train_loss: 0.0443, val_loss: 0.0113
Epoch 48 — train_loss: 0.0427, val_loss: 0.0113
Epoch 49 — train_loss: 0.0427, val_loss: 0.0096
Epoch 50 — train_loss: 0.0409, val_loss: 0.0104
Epoch 51 — train_loss: 0.0396, val_loss: 0.0082
Epoch 52 — train_loss: 0.0404, val_loss: 0.0086
Epoch 53 — train_loss: 0.0378, val_loss: 0.0090
Epoch 54 — train_loss: 0.0366, val_loss: 0.0083
Epoch 55 — train_loss: 0.0359, val_loss: 0.0079
Epoch 56 — train_loss: 0.0344, val_loss: 0.0069
Epoch 57 — train_loss: 0.0340, val_loss: 0.0072
Epoch 58 — train_loss: 0.0307, val_loss: 0.0075
Epoch 59 — train_loss: 0.0304, val_loss: 0.0072
Epoch 60 — train_loss: 0.0275, val_loss: 0.0075
Epoch 61 — train_loss: 0.0273, val_loss: 0.0062
Epoch 62 — train_loss: 0.0289, val_loss: 0.0057
Epoch 63 — train_loss: 0.0259, val_loss: 0.0054
Epoch 64 — train_loss: 0.0263, val_loss: 0.0061
Epoch 65 — train_loss: 0.0255, val_loss: 0.0058
Epoch 66 — train_loss: 0.0241, val_loss: 0.0052
Epoch 67 — train_loss: 0.0246, val_loss: 0.0058
Epoch 68 — train_loss: 0.0212, val_loss: 0.0051
Epoch 69 — train_loss: 0.0223, val_loss: 0.0053
Epoch 70 — train_loss: 0.0228, val_loss: 0.0070
Epoch 71 — train_loss: 0.0201, val_loss: 0.0038
Epoch 72 — train_loss: 0.0199, val_loss: 0.0046
Epoch 73 — train_loss: 0.0198, val_loss: 0.0052
Epoch 74 — train_loss: 0.0217, val_loss: 0.0044
Epoch 75 — train_loss: 0.0185, val_loss: 0.0047
Epoch 76 — train_loss: 0.0189, val_loss: 0.0042
Epoch 77 — train_loss: 0.0194, val_loss: 0.0051
Epoch 78 — train_loss: 0.0178, val_loss: 0.0039
→ Early stopping at epoch 78, no improvement for 7 epochs.
Total parameters: 4062631
Trainable parameters: 4062631
Model size (MB): 15.50
Testing phase...
Found 12630 test images across 43 clas



Test Accuracy: 97.08%
              precision    recall  f1-score   support

           0       1.00      0.98      0.99        60
           1       0.97      0.98      0.98       720
          10       1.00      1.00      1.00       660
          11       0.97      0.95      0.96       420
          12       1.00      1.00      1.00       690
          13       1.00      1.00      1.00       720
          14       0.90      1.00      0.95       270
          15       1.00      0.99      1.00       210
          16       1.00      1.00      1.00       150
          17       1.00      0.92      0.96       360
          18       0.99      0.93      0.96       390
          19       0.87      1.00      0.93        60
           2       0.96      0.98      0.97       750
          20       0.91      0.94      0.93        90
          21       0.83      0.94      0.88        90
          22       0.99      0.75      0.85       120
          23       0.95      0.97      0.96       150
          24       1.00      0.96      0.98        90
          25       0.91      0.97      0.94       480
          26       0.96      0.96      0.96       180
          27       0.74      0.48      0.59        60
          28       0.86      0.97      0.91       150
          29       0.90      0.98      0.94        90
           3       0.99      0.93      0.96       450
          30       0.90      0.92      0.91       150
          31       1.00      1.00      1.00       270
          32       1.00      1.00      1.00        60
          33       0.96      0.98      0.97       210
          34       0.92      1.00      0.96       120
          35       0.98      0.96      0.97       390
          36       0.98      0.97      0.98       120
          37       0.95      0.95      0.95        60
          38       0.99      1.00      0.99       690
          39       1.00      0.98      0.99        90
           4       0.98      0.98      0.98       660
          40       0.95      0.93      0.94        90
          41       0.98      0.98      0.98        60
          42       1.00      0.99      0.99        90
           5       0.93      0.97      0.95       630
           6       0.99      1.00      1.00       150
           7       0.99      0.98      0.99       450
           8       0.97      0.95      0.96       450
           9       0.99      1.00      1.00       480

    accuracy                           0.97     12630
   macro avg       0.96      0.96      0.96     12630
weighted avg       0.97      0.97      0.97     12630
